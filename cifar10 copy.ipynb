{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources:\n",
    "\n",
    "- [cifar10 (Colab)](https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/cifar10_tutorial.ipynb#scrollTo=ubQdOyR6FjUB)\n",
    "\n",
    "- [Iterative Pruning (Colab)](https://pytorch.org/tutorials/intermediate/pruning_tutorial.html)\n",
    "\n",
    "- [Pruning Experiments (Github)](https://github.com/olegpolivin/pruningExperiments/tree/main)\n",
    "- [Pruning Experiments (Medium)](https://olegpolivin.medium.com/experiments-in-neural-network-pruning-in-pytorch-c18d5b771d6d)\n",
    "- [Sparsifying Regularizer (Github)](https://github.com/dizam92/pyTorchReg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Components\n",
    "- data loading + preprocessing (/utils/data_utils.py ??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from regularizers.regularizer import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from utils.data_utils import preprocess\n",
    "from utils.training_utils import training_loop\n",
    "from utils.training_utils import package_model_components\n",
    "from utils.training_utils import calculate_regularizer_metrics\n",
    "from models.model import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "testloader,trainloader = preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_across_epochs = []\n",
    "latency_across_epochs = []\n",
    "list_of_regularizers = [NullRegularizer,L1Regularizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reload' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jason\\Desktop\\cs117 project\\projx\\D-EAP\\cifar10 copy.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jason/Desktop/cs117%20project/projx/D-EAP/cifar10%20copy.ipynb#X56sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mregularizers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mregularizer\u001b[39;00m \u001b[39mimport\u001b[39;00m NullRegularizer\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jason/Desktop/cs117%20project/projx/D-EAP/cifar10%20copy.ipynb#X56sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m reload(NullRegularizer)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jason/Desktop/cs117%20project/projx/D-EAP/cifar10%20copy.ipynb#X56sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m NullRegularizer(model\u001b[39m=\u001b[39mNet, lambda_reg\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jason/Desktop/cs117%20project/projx/D-EAP/cifar10%20copy.ipynb#X56sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# model_components = package_model_components(Net,list_of_regularizers)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'reload' is not defined"
     ]
    }
   ],
   "source": [
    "from regularizers.regularizer import NullRegularizer\n",
    "\n",
    "NullRegularizer(model=Net, lambda_reg=10**-2)\n",
    "\n",
    "# model_components = package_model_components(Net,list_of_regularizers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING CHANNEL\n",
    "\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # limit training time for debugging purposes\n",
    "        if i > 5:\n",
    "            break\n",
    "\n",
    "        #since we are not interested in inference, loss and latency can be calculated in one training loop\n",
    "        calculate_regularizer_metrics(model_components,inputs,labels)\n",
    "        # calculate_FLOPS()\n",
    "        print(i)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss_across_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(latency_across_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### PLOTTING FIGURES ########\n",
    "\n",
    "# -> utils/plotting_utils.py\n",
    "columns=[\"No Regularizer\",\"L1 Regularizer\"]\n",
    "df = pd.DataFrame(loss_across_epochs, columns=columns)\n",
    "print(df)\n",
    "plot = df.plot(title=\"Regularizer vs Loss\")\n",
    "plot.set(xlabel=\"Time/Iteration\", ylabel=\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns2=[\"No Regularizer\",\"L1 Regularizer\"]\n",
    "df2 = pd.DataFrame(latency_across_epochs, columns=columns2)\n",
    "print(df2)\n",
    "\n",
    "plot = df2.plot(title=\"Regularizer vs Latency\")\n",
    "plot.set(xlabel=\"Time/Iteration\", ylabel=\"Latency (s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> utils/evaluation_utils.py\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "net = Net()\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> utils/evaluation_utils.py\n",
    "\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
